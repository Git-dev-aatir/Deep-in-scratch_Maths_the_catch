# Neural Network Library (C++)

## ğŸ“ Overview  
This project implements a comprehensive neural network library in C++ with support for:
- Layer management (Dense, Activation)
- Optimization algorithms (SGD with momentum)
- Data handling (Dataset, DataLoader)
- Preprocessing utilities
- Loss functions and metrics
- Learning rate scheduling

## ğŸ”‘ Key Features  
- **Layers**: Dense, ReLU, Sigmoid, Tanh, Softmax  
- **Optimizers**: SGD with momentum and LR scheduling  
- **Data Handling**: Batch loading, shuffling, preprocessing  
- **Initialization**: Xavier, He, LeCun methods  
- **Losses**: MSE, MAE, Cross-Entropy, Hinge  
- **Utilities**: Activation functions, weight initialization  

## ğŸ“ Folder Structure  
```
project-root/
â”œâ”€â”€ include/               # Header files
â”‚   â”œâ”€â”€ Data/              # Dataset, DataLoader, Preprocessing
â”‚   â”œâ”€â”€ Layers/            # Layer implementations
â”‚   â”œâ”€â”€ Metrics/           # Loss functions and metrics
â”‚   â”œâ”€â”€ Models/            # Sequential model
â”‚   â”œâ”€â”€ Optimizers/        # Optimization algorithms
â”‚   â””â”€â”€ Utils/             # Utility functions
â”œâ”€â”€ src/                   # Implementation files
â”‚   â”œâ”€â”€ Data/              # Dataset/DataLoader implementations
â”‚   â”œâ”€â”€ Layers/            # Layer implementations
â”‚   â”œâ”€â”€ Metrics/           # Loss function implementations
â”‚   â”œâ”€â”€ Models/            # Sequential model implementation
â”‚   â”œâ”€â”€ Optimizers/        # Optimizer implementations
â”‚   â””â”€â”€ Utils/             # Utility implementations
â”œâ”€â”€ Journey/               # Documentation
â”‚   â”œâ”€â”€ Data/              # Data-related docs
â”‚   â”œâ”€â”€ Layers/            # Layer docs
â”‚   â”œâ”€â”€ Metrics/           # Metrics docs
â”‚   â”œâ”€â”€ Models/            # Model docs
â”‚   â”œâ”€â”€ Optimizers/        # Optimizer docs
â”‚   â””â”€â”€ Utils/             # Utility docs
â”œâ”€â”€ Examples/              # Usage examples
â”œâ”€â”€ Makefile               # Build configuration
â””â”€â”€ README.md              # This file
```

## ğŸ› ï¸ Building  
1. **Prerequisites**: C++17 compiler (GCC/Clang)  
2. **Build**:  
```bash
make
```

## â–¶ï¸ Running Examples  
To compile and run an example file:  
```bash
make run FILE=Examples/your_example.cpp
```
Replace `your_example.cpp` with your example file path relative to project root.

## ğŸ§¹ Cleaning Build Artifacts  
```bash
make clean
```

## âš ï¸ Note  
All file paths should be given relative to the project root directory.

## ğŸš€ Example Usage  
```cpp
#include "Models/Sequential.h"
#include "Layers/Layers.h"
#include "Optimizers/SGD.h"
#include "Metrics/Losses.h"

int main() {
    // Create network
    Sequential model(
        new DenseLayer(784, 256),
        new ActivationLayer(ActivationType::RELU),
        new DenseLayer(256, 10),
        new ActivationLayer(ActivationType::SOFTMAX)
    );

    // Initialize parameters
    model.initializeParameters(42);

    // Create optimizer
    SGD optim(0.01, 0.9); // LR=0.01, momentum=0.9

    // Training loop
    for (int epoch = 0; epoch < 10; epoch++) {
        double loss = model.train(X_train, y_train, optim, 64,
                                  Losses::cross_entropy_loss,
                                  Losses::cross_entropy_derivative);
        std::cout << "Epoch " << epoch << " loss: " << loss << "\n";
    }
    return 0;
}
```

## ğŸ“¦ Dependencies  
- C++17 standard library  
- STL components only (no external dependencies)  

## ğŸ“š Documentation  
Comprehensive documentation available in the `Journey/` directory:  
- Layer implementations  
- Optimization algorithms  
- Data handling  
- Utility functions  
- Model architecture  

## ğŸ“„ License  
This project is licensed under the MIT License. See [LICENSE](LICENSE) for details.